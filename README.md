<<<<<<< HEAD
# PayPal Pipeline Enterprise

<div align="center">

![Pipeline Status](https://img.shields.io/badge/pipeline-enterprise--ready-green)
![Python](https://img.shields.io/badge/python-3.11+-blue)
![Airflow](https://img.shields.io/badge/airflow-2.7+-orange)
![License](https://img.shields.io/badge/license-MIT-blue)

**Enterprise-grade ETL pipeline for PayPal transaction data processing**

</div>

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PayPal API    â”‚â”€â”€â”€â–¶â”‚  Data Pipeline   â”‚â”€â”€â”€â–¶â”‚   BigQuery DW   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  Cloud Storage   â”‚
                       â”‚   (Raw/Parsed)   â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ¯ Key Features

- âœ… **Infrastructure as Code** - Terraform automation
- âœ… **Containerized Deployment** - Docker & Docker Compose
- âœ… **Orchestrated Workflows** - Apache Airflow
- âœ… **Scalable Storage** - Google Cloud Storage
- âœ… **Data Warehouse** - BigQuery with partitioning
- âœ… **Data Quality** - Comprehensive validation
- âœ… **Enterprise Security** - Service accounts & encryption
- âœ… **Monitoring** - Logging, metrics & alerting

## ğŸ“ Project Structure

```
paypal-pipeline-enterprise/
â”œâ”€â”€ terraform/                 # Infrastructure as Code
â”‚   â”œâ”€â”€ main.tf               # Main Terraform configuration
â”‚   â”œâ”€â”€ variables.tf          # Variable definitions
â”‚   â”œâ”€â”€ outputs.tf            # Output definitions
â”‚   â””â”€â”€ terraform.tfvars.example
â”œâ”€â”€ docker/                   # Container configuration
â”‚   â”œâ”€â”€ Dockerfile            # Application container
â”‚   â”œâ”€â”€ requirements.txt      # Python dependencies
â”‚   â””â”€â”€ .dockerignore        # Docker ignore rules
â”œâ”€â”€ scripts/                  # ETL business logic
â”‚   â”œâ”€â”€ __init__.py          # Package initialization
â”‚   â”œâ”€â”€ fetch_transactions.py # PayPal data extraction
â”‚   â”œâ”€â”€ transform.py         # Data transformation
â”‚   â”œâ”€â”€ load_to_bq.py        # BigQuery loading
â”‚   â””â”€â”€ utils.py             # Common utilities
â”œâ”€â”€ dags/                    # Airflow orchestration
â”‚   â””â”€â”€ paypal_dag.py        # Main pipeline DAG
â”œâ”€â”€ config/                  # Configuration files
â”‚   â”œâ”€â”€ schema.json          # BigQuery table schema
â”‚   â””â”€â”€ pipeline_config.yaml # Pipeline configuration
â”œâ”€â”€ docker-compose.yml       # Multi-service orchestration
â”œâ”€â”€ .env.example            # Environment configuration template
â”œâ”€â”€ .gitignore              # Git ignore rules
â””â”€â”€ README.md               # Project documentation
```

## ğŸš€ Quick Start

### Prerequisites

- Docker and Docker Compose
- Google Cloud Platform account
- PayPal Developer account
- Terraform (for infrastructure deployment)

### 1. Environment Setup

```bash
# Clone the repository
git clone <repository-url>
cd paypal-pipeline-enterprise

# Copy environment template
cp .env.example .env

# Edit configuration
nano .env  # Update with your credentials
```

### 2. Infrastructure Deployment

```bash
# Navigate to Terraform directory
cd terraform

# Copy and edit Terraform variables
cp terraform.tfvars.example terraform.tfvars
nano terraform.tfvars

# Initialize and deploy infrastructure
terraform init
terraform plan
terraform apply
```

### 3. Service Account Setup

```bash
# Get service account key from Terraform output
terraform output -raw service_account_key | base64 -d > ../sa-key.json

# Set up environment variables (copy from terraform output)
terraform output setup_commands
```

### 4. Start the Pipeline

```bash
# Return to project root
cd ..

# Start all services
docker-compose up -d

# Check service status
docker-compose ps
```

### 5. Access Airflow UI

1. Open browser to `http://localhost:8080`
2. Login with credentials from `.env` file (default: airflow/airflow)
3. Enable the `paypal_data_pipeline` DAG
4. Trigger a manual run or wait for scheduled execution

## ğŸ”§ Configuration

### Environment Variables

Key environment variables in `.env`:

```bash
# GCP Configuration
GCP_PROJECT_ID=your-gcp-project-id
GCS_BUCKET=your-paypal-data-bucket
BQ_DATASET=paypal_data

# PayPal API
PAYPAL_CLIENT_ID=your_client_id
PAYPAL_CLIENT_SECRET=your_client_secret
PAYPAL_SANDBOX=true

# Pipeline Settings
ENVIRONMENT=dev
LOG_LEVEL=INFO
```

### Pipeline Configuration

Customize pipeline behavior in `config/pipeline_config.yaml`:

```yaml
paypal:
  api:
    timeout: 120
    max_retries: 3
    page_size: 500

data_quality:
  validation:
    enabled: true
    fail_on_error: false

monitoring:
  enabled: true
  metrics:
    - daily_transaction_count
    - pipeline_execution_time
```

## ğŸ”„ Pipeline Workflow

### 1. Extract (`fetch_transactions.py`)
- Connects to PayPal Reporting API
- Handles authentication and pagination
- Saves raw data to Cloud Storage
- Implements retry logic and error handling

### 2. Transform (`transform.py`)
- Parses raw PayPal JSON responses
- Normalizes data structure
- Validates data quality
- Converts to BigQuery-compatible format

### 3. Load (`load_to_bq.py`)
- Creates dataset and table if needed
- Loads data with partitioning
- Updates metadata timestamps
- Creates analytical views
- Validates loaded data

### 4. Orchestrate (`paypal_dag.py`)
- Schedules daily execution
- Manages task dependencies
- Handles error notifications
- Provides comprehensive monitoring

## ğŸ“Š Data Schema

### Transaction Table Structure

| Field | Type | Description |
|-------|------|-------------|
| `transaction_id` | STRING | Unique PayPal transaction ID |
| `transaction_date` | TIMESTAMP | Transaction timestamp |
| `amount` | FLOAT64 | Transaction amount |
| `currency_code` | STRING | Currency (USD, EUR, etc.) |
| `transaction_status` | STRING | Status (Success, Pending, etc.) |
| `payer_email` | STRING | Payer email address |
| `fee_amount` | FLOAT64 | PayPal processing fee |
| `net_amount` | FLOAT64 | Net amount after fees |
| `items` | RECORD | Repeated record of transaction items |

### Generated Views

- `daily_summary` - Daily transaction aggregations
- `payer_summary` - Customer transaction history
- `recent_transactions` - Last 7 days of transactions

## ğŸ› ï¸ Development

### Running Individual Scripts

```bash
# Extract data
docker-compose exec pipeline-runner python scripts/fetch_transactions.py \
  --start-date 2024-01-01 --end-date 2024-01-01 \
  --output-path /tmp/raw_data.json

# Transform data
docker-compose exec pipeline-runner python scripts/transform.py \
  --input-path /tmp/raw_data.json \
  --output-path /tmp/parsed_data.jsonl

# Load to BigQuery
docker-compose exec pipeline-runner python scripts/load_to_bq.py \
  --source-path /tmp/parsed_data.jsonl
```

### Testing

```bash
# Run tests
docker-compose exec pipeline-runner python -m pytest tests/

# Run with coverage
docker-compose exec pipeline-runner python -m pytest --cov=scripts tests/
```

### Code Quality

```bash
# Format code
docker-compose exec pipeline-runner black scripts/

# Lint code
docker-compose exec pipeline-runner flake8 scripts/

# Sort imports
docker-compose exec pipeline-runner isort scripts/
```

## ğŸ“ˆ Monitoring

### Airflow Monitoring

- **Web UI**: `http://localhost:8080`
- **Task Status**: View in Airflow Graph View
- **Logs**: Available in Airflow UI and local `logs/` directory

### Optional Monitoring Stack

Enable monitoring services:

```bash
# Start with monitoring profile
docker-compose --profile monitoring up -d

# Access Grafana
open http://localhost:3000  # admin/admin

# Access Prometheus
open http://localhost:9090
```

### Data Quality Metrics

The pipeline automatically generates:
- Transaction count validation
- Data completeness scores
- Duplicate detection
- Schema validation results

## ğŸ”’ Security

### Best Practices Implemented

- âœ… Service account authentication
- âœ… Secrets management via environment variables
- âœ… Network isolation with Docker networks
- âœ… Minimal container privileges
- âœ… Sensitive data masking in logs

### Security Checklist

- [ ] Rotate service account keys regularly
- [ ] Enable audit logging in GCP
- [ ] Use Cloud KMS for encryption keys
- [ ] Implement VPC for network security
- [ ] Set up Cloud Security Scanner

## ğŸš¨ Troubleshooting

### Common Issues

**Pipeline fails with authentication error:**
```bash
# Check service account key
docker-compose exec pipeline-runner cat /app/sa-key.json

# Verify GCP access
docker-compose exec pipeline-runner gcloud auth list
```

**Airflow UI not accessible:**
```bash
# Check Airflow services
docker-compose ps

# View Airflow logs
docker-compose logs airflow-webserver
```

**PayPal API rate limiting:**
- Reduce `page_size` in config
- Increase `retry_delay` in config
- Check PayPal API quotas

### Log Locations

- **Airflow Logs**: `logs/` directory
- **Container Logs**: `docker-compose logs <service>`
- **GCP Logs**: Cloud Logging in GCP Console

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Run code quality checks
6. Submit a pull request

### Development Setup

```bash
# Install development dependencies
pip install -r docker/requirements.txt

# Set up pre-commit hooks
pre-commit install

# Run full test suite
pytest tests/
```

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™‹ Support

- **Issues**: GitHub Issues
- **Documentation**: This README and inline code comments
- **Email**: tianxi.zhao@altardstate.com

---

<div align="center">

**Built with â¤ï¸ for enterprise IT teams**

</div># sofg_daily_paypal_info_load
=======
# sofg_daily_paypal_info_load
>>>>>>> 8a46f80ebdeb9fae2efc8113036baef15c97b860
